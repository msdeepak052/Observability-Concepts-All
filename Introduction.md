### ğŸ” What is Observability?

**Observability** is the ability to measure the **internal state of a system** based on the data it produces, like logs, metrics, and traces. It helps you **understand what's happening inside** your application or infrastructure **without modifying** it.

It answers:

* **Whatâ€™s broken?**
* **Why is it broken?**
* **Where is the issue happening?**
* **How is performance trending over time?**

# ğŸ’¡ Introduction to Observability
- Observability is the ability to understand the internal state of a system by analyzing the data it produces, including logs, metrics, and traces.

- Monitoring(Metrics): involves tracking system metrics like CPU usage, memory usage, and network performance. Provides alerts based on predefined thresholds and conditions
    - `Monitoring tells us what is happening.`
- Logging(Logs):  involves the collection of log data from various components of a system.
    - `Logging explains why it is happening.`
- Tracing(Traces): involves tracking the flow of a request or transaction as it moves through different services and components within a system.
    - `Tracing shows how it is happening.`

---
![Introduction-to-Observability](https://github.com/user-attachments/assets/c0a48335-b516-4667-85cd-1dfeb779f2ba)

---

### âœ… Why Observability is Needed

In modern **cloud-native** and **microservices-based** environments like **Kubernetes**, systems are:

* Distributed
* Dynamic (containers come and go)
* Complex (inter-service communication)

Observability is **critical** to:

* Detect issues **proactively** (before users do)
* **Debug incidents** quickly
* **Optimize performance**
* Ensure **service-level objectives (SLOs)** and **uptime**

---

### ğŸ§± Core Pillars of Observability

| Pillar      | Description                                           | Example (K8s)                          |
| ----------- | ----------------------------------------------------- | -------------------------------------- |
| **Logs**    | Text-based records of events or messages              | Container logs from a failing pod      |
| **Metrics** | Numeric measurements over time                        | CPU/memory usage of pods, requests/sec |
| **Traces**  | Detailed path of a request across services/components | Distributed tracing in microservices   |

---

### ğŸ“¦ Real-Life Scenarios in Kubernetes

---

#### ğŸ§© Scenario 1: **A Pod is Restarting Frequently**

* **Logs**: View pod logs (`kubectl logs`) to find crash errors.
* **Metrics**: Monitor restart count via Prometheus/Grafana.
* **Trace**: If service call failed upstream, Jaeger trace shows call path.

> **Without observability**: Youâ€™d only see the pod status as `CrashLoopBackOff`.
> **With observability**: You discover itâ€™s a failed DB connection due to a wrong secret.

---

#### ğŸ§© Scenario 2: **API Response Latency is Increasing**

* **Metrics**: Show average response time is up for service `user-api`.
* **Trace**: Jaeger shows slow DB query inside request chain.
* **Logs**: Show query timeout or bad indexing.

> Result: Fix DB query or scale service.

---

#### ğŸ§© Scenario 3: **CPU Spike in a Node**

* **Metrics**: Node exporter + Prometheus shows CPU% > 95%
* **Logs**: App logs show excessive processing due to a malformed request.
* **Trace**: Confirms the spike is tied to specific request route.

---

### ğŸ”§ Observability Tools in K8s

| Tool                                       | Purpose                                |
| ------------------------------------------ | -------------------------------------- |
| **Prometheus**                             | Metrics collection                     |
| **Grafana**                                | Metrics visualization                  |
| **Elasticsearch + Fluentd + Kibana (EFK)** | Centralized logging                    |
| **Jaeger**                                 | Distributed tracing                    |
| **Kiali**                                  | Service mesh observability (for Istio) |
| **Lens**                                   | K8s dashboard with logs and metrics    |

---

### ğŸ› ï¸ Kubernetes Example Setup

```yaml
# Sample Prometheus pod annotation for scraping metrics
metadata:
  annotations:
    prometheus.io/scrape: 'true'
    prometheus.io/port: '8080'
```

---

### ğŸ¯ Summary

Observability in Kubernetes helps **understand, debug, and improve** distributed systems. It combines logs, metrics, and traces to give **full visibility** into your appâ€™s behavior.

Letâ€™s break down **Observability** from first principles, and make it deeply intuitive.

---

## ğŸ” What is Observability?

At its core:

> **Observability is the ability to understand what is happening inside a system just by looking at the outputs it produces.**

Imagine your system is a **car**. If the engine light turns on, the speedometer reads zero, and there's a trail of smoke behind you, these **external signals** give you clues about **internal issues**â€”like a misfiring piston or a broken exhaust. Thatâ€™s observability.

In software systems, especially **distributed systems** like **Kubernetes (K8s)**, it's **impossible to "look inside" directly**. Observability is how we "listen to the engine", watch the dials, and check the exhaust fumesâ€”**logs, metrics, and traces** are our dashboard.

---

## ğŸ¤– Observability vs. Monitoring

* **Monitoring** asks predefined **questions**:

  > â€œIs memory usage > 90%?â€
* **Observability** enables **new, unanticipated questions**:

  > â€œWhy did this pod suddenly crash, even though CPU and memory were fine?â€

Think of monitoring as a **burglar alarm**, and observability as a **forensics lab**. Monitoring alerts you when somethingâ€™s wrong. Observability tells you **why** and **how** it happened.

---

## ğŸ› ï¸ The Three Pillars of Observability

These are the **3 outputs** that together allow us to understand system behavior.

### 1. ğŸ“ˆ **Metrics**

* **What it is**: Numbers over time. e.g., CPU usage, number of requests per second.
* **Analogy**: Like your **heart rate or temperature**. It tells you that something is off, but not what exactly.
* **In K8s**: Metrics from Prometheus can show the memory usage of a Pod over time.

### 2. ğŸ“„ **Logs**

* **What it is**: Immutable, timestamped records of events.
* **Analogy**: Like a **black box recorder** in an airplane.
* **In K8s**: Logs from a Pod might say `Error: cannot connect to database`, which gives a clue about the failure.

### 3. ğŸ”— **Traces**

* **What it is**: Records of how a single request flows through multiple services.
* **Analogy**: Like **tracking a pizza order** from kitchen â†’ driver â†’ your door.
* **In K8s**: A trace might show that an API call took 2s at the frontend, but 1.9s was spent waiting on the database.

---

## ğŸŒ Real-world Need for Observability

### Problem:

You're running a **microservices-based app** on Kubernetes. It has 50 services. A user complains: *"The checkout page takes forever!"*

Without observability, this is a **needle in a haystack** problem.

With observability:

1. **Trace** shows the request went through frontend â†’ cart â†’ payment â†’ shipping.
2. You see the **latency** is in `payment`.
3. Logs show `payment` is failing to reach `bank-gateway`.
4. Metrics show a **network spike** affecting that Pod's node.

âœ… Problem diagnosed in minutes, not days.

---

## ğŸ“¦ Observability in Kubernetes (K8s)

Letâ€™s go deep into an example:

### ğŸ” Use case: Debugging a crash-looping Pod

#### Scenario:

You deploy a new microservice to your Kubernetes cluster. It goes into `CrashLoopBackOff`. You have **no idea why**.

Without observability: you're guessing in the dark.

With observability:

### ğŸ§© Step-by-step:

1. **Log Aggregation (e.g. Fluentd + Elasticsearch + Kibana)**:

   * You tail the Pod logs.
   * You see: `Exception: cannot connect to Redis`.

2. **Metrics (e.g. Prometheus + Grafana)**:

   * You query Redis service metrics.
   * Memory and CPU are fine, but **connection count is maxed**.

3. **Traces (e.g. OpenTelemetry + Jaeger)**:

   * You trace request paths.
   * Shows 95% of requests hang at `getSession()` in Redis call.

4. **Kubernetes Metadata**:

   * You correlate logs/metrics to Pod labels.
   * You discover that your new microservice was **deployed without the correct Redis authentication config**.

ğŸš€ With full observability:

* You **see symptoms (metrics)**,
* **Understand behavior (logs)**,
* And **trace the exact request path (traces)**.

---

## ğŸ—ï¸ Why Observability is Crucial for K8s

Kubernetes is **ephemeral** and **dynamic**:

* Pods spin up and down constantly.
* Services autoscale.
* Nodes crash and restart.
* Networking is abstracted and complex.

### Analogy:

Imagine you're managing **a fleet of self-driving delivery drones**. They're always in motion, dynamically rerouting, sometimes crashing in midair. You **need telemetry, logs, and flight paths** to make sense of why things go wrong. That's observability in Kubernetes.

---

## ğŸ“˜ TL;DR

| Concept       | What it is                            | Analogy                           | K8s Example                                |
| ------------- | ------------------------------------- | --------------------------------- | ------------------------------------------ |
| Observability | Understand internal state via outputs | Car dashboard, airplane black box | Diagnose crashing Pods                     |
| Metrics       | Quantitative measurements over time   | Heart rate monitor                | CPU, memory, request count                 |
| Logs          | Textual event records                 | Black box flight recorder         | `Error: DB connection failed`              |
| Traces        | Request flows across services         | Pizza delivery route tracking     | Trace user login through multiple services |

---

![Introduction to Observability](images/Introduction-to-Observability.png)

## ğŸ¤” Why Monitoring?
- Monitoring helps us keep an eye on our systems to ensure they are working properly.
- Perpose:  maintaining the **health, performance, and security** of IT environments.
- It enables early detection of issues, ensuring that they can be addressed before causing significant downtime or data loss.

- We use monitoring to:
    - Detect Problems Early
    - Measure Performance:
    - Ensure Availability:

## ğŸ¤” Why Observability?
- Observability helps us understand why our systems are behaving the way they are.
- Itâ€™s like having a detailed map and tools to explore and diagnose issues.

- We use observability to:
    - Diagnose Issues:
    - Understand Behavior:
    - Improve Systems:

![why-monitoring-why-observability](https://github.com/user-attachments/assets/1f2ecccb-f596-4ec9-b994-731343112303)



## ğŸ†š What is the Exact Difference Between Monitoring and Observability?
- ğŸ”¥ Monitoring is the *`when and what`* of a system error, and observability is the *`why and how`*

| Category       | Monitoring                                   | Observability                                         |
|----------------|----------------------------------------------|------------------------------------------------------|
| Focus          | Checking if everything is working as expected| Understanding why things are happening in the system  |
| Data           | Collects metrics like CPU usage, memory usage, and error rates | Collects logs, metrics, and traces to provide a full picture |
| Alerts         | Sends notifications when something goes wrong| Correlates events and anomalies to identify root causes |
| Example        | If a server's CPU usage goes above 90%, monitoring will alert us | If a website is slow, observability helps us trace the user's request through different services to find the bottleneck |
| Insight        | Identifies potential issues before they become critical | Helps diagnose issues and understand system behavior |


## ğŸ”­ Does Observability Cover Monitoring?
- Yes!! Monitoring is subset of Observability
- Observability is a broader concept that includes monitoring as one of its components.
- monitoring focuses on tracking specific metrics and alerting on predefined conditions
- observability provides a comprehensive understanding of the system by collecting and analyzing a wider range of data, including **logs, metrics, and traces**.

## ğŸ–¥ï¸ What Can Be Monitored?
- Infrastructure: CPU usage, memory usage, disk I/O, network traffic.
- Applications: Response times, error rates, throughput.
- Databases: Query performance, connection pool usage, transaction rates.
- Network: Latency, packet loss, bandwidth usage.
- Security: Unauthorized access attempts, vulnerability scans, firewall logs.

## ğŸ‘€ What Can Be Observed?
- Logs: Detailed records of events and transactions within the system.
- Metrics: Quantitative data points like CPU load, memory consumption, and request counts.
- Traces: Data that shows the flow of requests through various services and components.

## ğŸ†š Monitoring on Bare-Metal Servers vs. Monitoring Kubernetes
- Bare-Metal Servers:
    - Direct Access: Easier access to hardware metrics and logs.
    - Fewer Layers: Simpler environment with fewer abstraction layers.

- Kubernetes:
    - Dynamic Environment: Challenges with monitoring ephemeral containers and dynamic scaling.
    - Distributed Nature: Requires tools that can handle distributed systems and correlate data from multiple sources.

## ğŸ†š Observing on Bare-Metal Servers vs. Observing Kubernetes
- Bare-Metal Servers:
    - Simpler Observability: Easier to collect and correlate logs, metrics, and traces due to fewer components and layers.

- Kubernetes:
    - Complex Observability: Requires sophisticated tools to handle the dynamic and distributed nature of containers and microservices.
    - Integration: Necessitates the integration of multiple observability tools to get a complete picture of the system.

## âš’ï¸ What are the Tools Available?
- **Monitoring Tools**: Prometheus, Grafana, Nagios, Zabbix, PRTG.
- **Observability Tools**: ELK Stack (Elasticsearch, Logstash, Kibana), EFK Stack (Elasticsearch, FluentBit, Kibana) Splunk, Jaeger, Zipkin, New Relic, Dynatrace, Datadog.




